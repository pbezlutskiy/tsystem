# tbank_api/optimized_data_manager.py
"""
–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π
"""

import pandas as pd
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import logging

# ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–´–ô –ò–ú–ü–û–†–¢ PSUTIL –° –û–ë–†–ê–ë–û–¢–ö–û–ô –û–®–ò–ë–û–ö
try:
    import psutil
    PSUTIL_AVAILABLE = True
except ImportError:
    PSUTIL_AVAILABLE = False
    logging.debug("psutil –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø–∞–º—è—Ç–∏ –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω.")

from .tbank_api import TBankAPI
from .tbank_cache import TBankCache, CacheConfig
from .cache_optimizer import SafeCacheOptimizer
from .advanced_analytics import AdvancedCacheAnalytics
from .smart_predictor import SmartPredictor
from .auto_optimizer import AutoOptimizer

logger = logging.getLogger(__name__)

class OptimizedTBankDataManager:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π"""
    
    def __init__(self, api_key: str = None):
        self.api = TBankAPI(api_key)
        self.cache = TBankCache()
        self.optimizer = SafeCacheOptimizer()
        self.available_symbols = None
        
        # ‚úÖ –ò–ù–ò–¶–ò–ê–õ–ò–ó–ò–†–£–ï–ú –†–ê–°–®–ò–†–ï–ù–ù–£–Æ –ê–ù–ê–õ–ò–¢–ò–ö–£
        self.advanced_analytics = AdvancedCacheAnalytics(self)
        
        self.performance_stats = {
            'total_requests': 0,
            'cache_hits': 0,
            'cache_misses': 0,
            'optimization_savings_mb': 0.0
        }
        
         # ‚úÖ –î–û–ë–ê–í–õ–Ø–ï–ú –£–ú–ù–´–ô –ü–†–ï–î–°–ö–ê–ó–ê–¢–ï–õ–¨ –ò –ê–í–¢–û–û–ü–¢–ò–ú–ò–ó–ê–¢–û–†
        self.smart_predictor = SmartPredictor(self)
        self.auto_optimizer = AutoOptimizer(self)
        
        logger.info("‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä —Å AI-–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def get_historical_data_with_cache(self, symbol: str, 
                                     start_date: str, 
                                     end_date: str = None,
                                     timeframe: str = '1d',
                                     use_cache: bool = True) -> pd.DataFrame:
        """
        –£–ª—É—á—à–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–æ–π
        """
        self.performance_stats['total_requests'] += 1
        
        if not use_cache:
            return self.api.get_historical_data(symbol, start_date, end_date, timeframe)
            
        # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –¥–∞—Ç
        from_dt = datetime.strptime(start_date, '%Y-%m-%d')
        to_dt = datetime.strptime(end_date, '%Y-%m-%d') if end_date else datetime.now()
        
        # –ü–æ–ª—É—á–∞–µ–º FIGI
        figi = self.api._get_figi_by_ticker(symbol)
        if not figi:
            logger.error(f"FIGI –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è {symbol}")
            return pd.DataFrame()
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑ –∫—ç—à–∞
        cached_data = self.cache.load_candles(figi, timeframe, from_dt, to_dt)
        if cached_data is not None and not cached_data.empty:
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ –∏–∑ –∫—ç—à–∞: {symbol} ({len(cached_data)} –∑–∞–ø–∏—Å–µ–π)")
            self.performance_stats['cache_hits'] += 1
            return cached_data
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑ API
        logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑ API: {symbol}")
        self.performance_stats['cache_misses'] += 1
        
        api_data = self.api.get_historical_data(symbol, start_date, end_date, timeframe)
        
        if api_data.empty:
            return pd.DataFrame()
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö
        original_size = api_data.memory_usage(deep=True).sum() / 1024 / 1024
        optimized_data = self.optimizer.optimize_dataframe_safe(api_data)
        
        # –õ–æ–≥–∏—Ä—É–µ–º —ç–∫–æ–Ω–æ–º–∏—é –º–µ—Å—Ç–∞
        optimized_size = optimized_data.memory_usage(deep=True).sum() / 1024 / 1024
        savings = original_size - optimized_size
        if savings > 0:
            self.performance_stats['optimization_savings_mb'] += savings
            logger.info(f"üíæ –≠–∫–æ–Ω–æ–º–∏—è –ø–∞–º—è—Ç–∏: {savings:.2f} MB –¥–ª—è {symbol}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –∫—ç—à
        self.cache.save_candles(figi, timeframe, optimized_data, (from_dt, to_dt))
        
        return api_data
    
    # ===== –†–ê–°–®–ò–†–ï–ù–ù–ê–Ø –ê–ù–ê–õ–ò–¢–ò–ö–ê =====
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """–ë–∞–∑–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        total_requests = self.performance_stats['total_requests']
        cache_hits = self.performance_stats['cache_hits']
        
        hit_ratio = (cache_hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            'total_requests': total_requests,
            'cache_hits': cache_hits,
            'cache_misses': self.performance_stats['cache_misses'],
            'cache_hit_ratio': f"{hit_ratio:.1f}%",
            'memory_savings_mb': round(self.performance_stats['optimization_savings_mb'], 2),
            'avg_savings_per_request': round(
                self.performance_stats['optimization_savings_mb'] / max(1, total_requests), 4
            )
        }

    def get_detailed_analytics(self) -> Dict[str, Any]:
        """–î–µ—Ç–∞–ª—å–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏"""
        cache_stats = self.cache.get_cache_stats()
        performance_stats = self.get_performance_stats()
        
        try:
            # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
            advanced_trends = self.advanced_analytics.get_performance_trends()
            active_alerts = self.advanced_analytics.get_active_alerts()
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏: {e}")
            advanced_trends = {
                'hit_ratio_trend': 'stable',
                'response_time_trend': 'stable', 
                'active_alerts': 0,
                'uptime_hours': 0,
                'data_points': 0
            }
            active_alerts = []
        
        # ‚úÖ –ë–ï–ó–û–ü–ê–°–ù–û–ï –ü–û–õ–£–ß–ï–ù–ò–ï –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø –ü–ê–ú–Ø–¢–ò
        memory_usage = 0
        if PSUTIL_AVAILABLE:
            try:
                process = psutil.Process()
                memory_usage = process.memory_info().rss / 1024 / 1024  # MB
            except Exception as e:
                logger.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {e}")
        else:
            logger.debug("psutil –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏ –Ω–µ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç—Å—è")
        
        return {
            **cache_stats,
            **performance_stats,
            **advanced_trends,
            'memory_usage_mb': round(memory_usage, 2),
            'active_alerts_count': len(active_alerts),
            'optimization_level': 'advanced',
            'status': 'active',
            'features': {
                'advanced_analytics': True,
                'performance_monitoring': True,
                'real_time_metrics': True,
                'memory_monitoring': PSUTIL_AVAILABLE
            }
        }

    def get_advanced_analytics(self) -> Dict[str, Any]:
        """–ü–æ–ª–Ω–∞—è —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è –∞–Ω–∞–ª–∏—Ç–∏–∫–∞"""
        return {
            'basic_stats': self.get_performance_stats(),
            'cache_info': self.cache.get_cache_stats(),
            'advanced_trends': self.advanced_analytics.get_performance_trends(),
            'active_alerts': self.advanced_analytics.get_active_alerts(),
            'metrics_history': {
                'hit_ratio': self.advanced_analytics.get_metrics_history('hit_ratio', 10),
                'response_time': self.advanced_analytics.get_metrics_history('response_time', 10)
            }
        }
    
    def acknowledge_alert(self, alert_index: int):
        """–ü–æ–¥—Ç–≤–µ—Ä–¥–∏—Ç—å –∞–ª–µ—Ä—Ç –≤ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–µ"""
        self.advanced_analytics.acknowledge_alert(alert_index)
    
    # ===== –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ –° –°–£–©–ï–°–¢–í–£–Æ–©–ò–ú –ö–û–î–û–ú =====
    
    def get_instruments_with_cache(self, instrument_type: str = None, 
                                 force_refresh: bool = False) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        cache_key = instrument_type or "all"
        
        if not force_refresh:
            cached_instruments = self.cache.load_instruments(cache_key)
            if cached_instruments is not None and not cached_instruments.empty:
                logger.info(f"‚úÖ –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –∏–∑ –∫—ç—à–∞: {cache_key}")
                return cached_instruments
        
        logger.info(f"üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –∏–∑ API: {cache_key}")
        api_instruments = self.api.get_instruments_list(instrument_type)
        
        if api_instruments.empty:
            return pd.DataFrame()
        
        self.cache.save_instruments(api_instruments, cache_key)
        return api_instruments
    
    def get_available_symbols_cached(self, force_refresh: bool = False) -> pd.DataFrame:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ —Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        if self.available_symbols is None or force_refresh:
            self.available_symbols = self.get_instruments_with_cache(force_refresh=force_refresh)
        return self.available_symbols
    
    def update_data_incrementally(self, symbol: str, 
                                days_back: int = 1,
                                timeframe: str = '1d') -> pd.DataFrame:
        """–ò–Ω–∫—Ä–µ–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        fresh_data = self.api.get_historical_data(
            symbol=symbol,
            start_date=start_date.strftime('%Y-%m-%d'),
            end_date=end_date.strftime('%Y-%m-%d'),
            timeframe=timeframe
        )
        
        if fresh_data.empty:
            logger.warning(f"–ù–µ—Ç —Å–≤–µ–∂–∏—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {symbol}")
            return pd.DataFrame()
        
        figi = self.api._get_figi_by_ticker(symbol)
        if not figi:
            return fresh_data
        
        updated_data = self.cache.update_candles_incrementally(figi, timeframe, fresh_data)
        return updated_data
    
    def search_instruments_cached(self, query: str) -> pd.DataFrame:
        """–ü–æ–∏—Å–∫ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ –≤ –∫—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–º —Å–ø–∏—Å–∫–µ"""
        symbols_df = self.get_available_symbols_cached()
        if symbols_df.empty:
            return pd.DataFrame()
        
        mask = (symbols_df['symbol'].str.contains(query, case=False, na=False) | 
                symbols_df['name'].str.contains(query, case=False, na=False))
        
        return symbols_df[mask].copy()
    
    def get_cache_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–æ—Å—Ç–æ—è–Ω–∏–∏ –∫—ç—à–∞"""
        return self.cache.get_cache_stats()
    
    def clear_all_cache(self):
        """–û—á–∏—Å—Ç–∫–∞ –≤—Å–µ–≥–æ –∫—ç—à–∞"""
        self.cache.clear_cache()
        self.available_symbols = None
    
    def is_symbol_available(self, symbol: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ —Å–∏–º–≤–æ–ª–∞"""
        symbols_df = self.get_available_symbols_cached()
        return not symbols_df.empty and symbol in symbols_df['symbol'].values
    
    # –î–û–ë–ê–í–¨–¢–ï –ù–û–í–´–ï –ú–ï–¢–û–î–´:
    def preload_data(self, symbol: str, timeframe: str, days_back: int = 30):
        """–ü—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö"""
        from datetime import datetime, timedelta
        
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        try:
            data = self.api.get_historical_data(
                symbol, 
                start_date.strftime('%Y-%m-%d'),
                end_date.strftime('%Y-%m-%d'),
                timeframe
            )
            
            if not data.empty:
                figi = self.api._get_figi_by_ticker(symbol)
                if figi:
                    optimized_data = self.optimizer.optimize_dataframe_safe(data)
                    self.cache.save_candles(figi, timeframe, optimized_data, (start_date, end_date))
                    logger.info(f"‚úÖ –ü—Ä–µ–¥–∑–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol}")
                    
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥–∑–∞–≥—Ä—É–∑–∫–∏ {symbol}: {e}")
    
    def get_prediction_stats(self) -> Dict[str, Any]:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π"""
        return self.smart_predictor.get_prediction_stats()
    
    def get_optimization_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è—Ö"""
        return {
            'auto_optimization_enabled': self.auto_optimizer.config['optimization_enabled'],
            'optimization_history_count': len(self.auto_optimizer.optimization_history),
            'last_optimization': self.auto_optimizer.last_optimization
        }    